{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beautiful Soup\n",
    "\n",
    "[Site to scrape](https://en.wikipedia.org/wiki/Lists_of_legendary_creatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/Lists_of_legendary_creatures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = requests.get(url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphaList = soup.find_all('ul')[1]\n",
    "print(alphaList.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listPageLinks = [a['href'] for a in alphaList.find_all('a')]\n",
    "listPageLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newUrl = f'https://en.wikipedia.org{listPageLinks[0]}'\n",
    "print(newUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "newSoup = BeautifulSoup(requests.get(newUrl).text, 'html.parser')\n",
    "newSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newSoup.find_all('ul')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "creatureList = newSoup.find_all('ul')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCreature = creatureList.find_all('li')[0]\n",
    "testCreature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCreature.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCreature.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = testCreature.find('a').text\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageLink = testCreature.find('a')['href']\n",
    "pageLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = re.findall(r\"\\((.*)\\)\", testCreature.__str__())[0]\n",
    "origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "originSoup = BeautifulSoup(origin)\n",
    "originName = originSoup.find('a').text\n",
    "originName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "originLink = originSoup.find('a')['href']\n",
    "originLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_creature(creature):\n",
    "    name = creature.find('a').text\n",
    "    pageLink = creature.find('a')['href']\n",
    "    origin = re.findall(r\"\\((.*)\\)\", creature.__str__())[0]\n",
    "    originSoup = BeautifulSoup(origin)\n",
    "    originNames = [a.text for a in originSoup.find_all('a')]\n",
    "    originLinks = [a['href'] for a in originSoup.find_all('a')]\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"pageLink\": pageLink,\n",
    "        \"originNames\": originNames,\n",
    "        \"originLinks\": originLinks\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_creature(testCreature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for creature in creatureList.find_all('li'):\n",
    "    print(parse_creature(creature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aCreatures = [parse_creature(creature) for creature in creatureList.find_all('li')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(aCreatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_creature_page(url):\n",
    "    R = requests.get(url)\n",
    "    soup = BeautifulSoup(R.text, 'html.parser')\n",
    "    creatureList = soup.find_all('ul')[1]\n",
    "    creatures = [parse_creature(creature) for creature in creatureList.find_all('li')]\n",
    "    return creatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scrape_creature_page(f'https://en.wikipedia.org{listPageLinks[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_creature(creature):\n",
    "    name = creature.find('a').text\n",
    "    pageLink = creature.find('a')['href']\n",
    "    try:\n",
    "        origin = re.findall(r\"\\((.*)\\)\", creature.__str__())[0]\n",
    "        originSoup = BeautifulSoup(origin)\n",
    "        originNames = [a.text for a in originSoup.find_all('a')]\n",
    "        originLinks = [a['href'] for a in originSoup.find_all('a')]\n",
    "    except IndexError:\n",
    "        originNames = []\n",
    "        originLinks = []\n",
    "        print(f\"No origin found in {creature.__str__()}\")\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"pageLink\": pageLink,\n",
    "        \"originNames\": originNames,\n",
    "        \"originLinks\": originLinks\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scrape_creature_page(f'https://en.wikipedia.org{listPageLinks[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allCreatures = []\n",
    "for link in listPageLinks:\n",
    "    allCreatures.extend(scrape_creature_page(f\"https://en.wikipedia.org{link}\"))\n",
    "    time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_creature(creature):\n",
    "    try:\n",
    "        name = creature.find('a').text\n",
    "        pageLink = creature.find('a')['href']\n",
    "    except AttributeError:\n",
    "        name = \"\"\n",
    "        pageLink = \"\"\n",
    "        print(f\"Could not find link in {creature}\")\n",
    "    try:\n",
    "        origin = re.findall(r\"\\((.*)\\)\", creature.__str__())[0]\n",
    "        originSoup = BeautifulSoup(origin)\n",
    "        originNames = [a.text for a in originSoup.find_all('a')]\n",
    "        originLinks = [a['href'] for a in originSoup.find_all('a')]\n",
    "    except IndexError:\n",
    "        originNames = []\n",
    "        originLinks = []\n",
    "        print(f\"No origin found in {creature}\")\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"pageLink\": pageLink,\n",
    "        \"originNames\": originNames,\n",
    "        \"originLinks\": originLinks\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allCreatures = []\n",
    "for link in listPageLinks:\n",
    "    allCreatures.extend(scrape_creature_page(f\"https://en.wikipedia.org{link}\"))\n",
    "    time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_creature(creature):\n",
    "    try:\n",
    "        name = creature.find('a').text\n",
    "        pageLink = creature.find('a')['href']\n",
    "    except AttributeError:\n",
    "        name = \"\"\n",
    "        pageLink = \"\"\n",
    "        print(f\"Could not find link in {creature}\")\n",
    "    try:\n",
    "        origin = re.findall(r\"\\((.*)\\)\", creature.__str__())[0]\n",
    "        originSoup = BeautifulSoup(origin)\n",
    "        originNames = [a.text for a in originSoup.find_all('a')]\n",
    "        originLinks = [a['href'] for a in originSoup.find_all('a')]\n",
    "    except IndexError:\n",
    "        originNames = []\n",
    "        originLinks = []\n",
    "        print(f\"No origin found in {creature}\")\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"pageLink\": pageLink,\n",
    "        \"originNames\": originNames,\n",
    "        \"originLinks\": originLinks,\n",
    "        \"sourceText\": creature.__str__()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allCreatures = []\n",
    "for link in listPageLinks:\n",
    "    allCreatures.extend(scrape_creature_page(f\"https://en.wikipedia.org{link}\"))\n",
    "    time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(allCreatures)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9cd76759bde257768d40c4d32c53d7440e94e563219d28f651a570c7a44427a2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
